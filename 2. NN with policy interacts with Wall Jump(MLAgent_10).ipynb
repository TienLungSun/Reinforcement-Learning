{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2. NN with policy interacts with 3D Ball (MLAgent 10).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TienLungSun/Intelligent-Robot/blob/main/LearnPPO-AC/2.%20NN%20with%20policy%20interacts%20with%20Wall%20Jump(MLAgent_10).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRObB0mXmZhq"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Normal\n",
        "import numpy as np\n",
        "\n",
        "from mlagents_envs.environment import UnityEnvironment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTDJ8jn3mZh5",
        "outputId": "2903d42b-7074-42d1-baaa-9fd1da0b86da"
      },
      "source": [
        "if(torch.cuda.is_available()):\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(device, torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device= torch.device(\"cpu\")\n",
        "    print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda GeForce GTX 1660 SUPER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMHvWbuLuJSc"
      },
      "source": [
        "### Connect to Unity to examine two types of behavior names and their state and action design "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mgdak621uJSd"
      },
      "source": [
        "env = UnityEnvironment(file_name= None, base_port=5004)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyCXS-u6uJSe",
        "outputId": "69dce997-a7f3-4018-a554-5ad16d26c2d4"
      },
      "source": [
        "# we see only one behavior name at first time\n",
        "env.reset()\n",
        "behaviorNames = list(env.behavior_specs.keys())\n",
        "print(behaviorNames)\n",
        "for behaviorName in behaviorNames:\n",
        "    behavior_spec = env.behavior_specs[behaviorName]\n",
        "    print(behaviorName, behavior_spec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['SmallWallJump?team=0']\n",
            "SmallWallJump?team=0 BehaviorSpec(observation_shapes=[(210,), (210,), (24,)], action_spec=ActionSpec(continuous_size=0, discrete_branches=(3, 3, 3, 2)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNooUkqsuJSf",
        "outputId": "a413858b-7661-4108-e87a-b814dcf50ea1"
      },
      "source": [
        "# after 2nd reset, we can see two behaivor names\n",
        "env.reset()\n",
        "behaviorNames = list(env.behavior_specs.keys())\n",
        "print(behaviorNames)\n",
        "for behaviorName in behaviorNames:\n",
        "    behavior_spec = env.behavior_specs[behaviorName]\n",
        "    print(behaviorName, behavior_spec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['SmallWallJump?team=0', 'BigWallJump?team=0']\n",
            "SmallWallJump?team=0 BehaviorSpec(observation_shapes=[(210,), (210,), (24,)], action_spec=ActionSpec(continuous_size=0, discrete_branches=(3, 3, 3, 2)))\n",
            "BigWallJump?team=0 BehaviorSpec(observation_shapes=[(210,), (210,), (24,)], action_spec=ActionSpec(continuous_size=0, discrete_branches=(3, 3, 3, 2)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89hu-iCguJSg"
      },
      "source": [
        "env.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb8F0fJLuJSh"
      },
      "source": [
        "### Define and generate NN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrBlsgb_mZh9"
      },
      "source": [
        "N_STATES  = 444  # 210+210+24\n",
        "N_ACTIONS =4     # 4 branches\n",
        "N_AGENTS = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nq51-A-mZh-",
        "outputId": "7b967e0a-3d55-4a0f-84ef-7482065dd459"
      },
      "source": [
        "#test: tensor of size (1, N_Actions)\n",
        "a = torch.ones(1, N_ACTIONS)\n",
        "print(a, a.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1., 1.]]) torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AxgxcqRmZh_",
        "outputId": "ca5f011e-2d06-4ba6-9fc7-775fe530bae7"
      },
      "source": [
        "#test: NN parameter with gradients\n",
        "b = nn.Parameter(torch.ones(1, N_ACTIONS) * 0.0)\n",
        "print(b, b.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[0., 0., 0., 0.]], requires_grad=True) torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mgn-NTTmZiB",
        "outputId": "4da40f07-18e8-4045-c3e4-dfb461b6f2cd"
      },
      "source": [
        "#test: generate a NN parameter [0, 0]\n",
        "log_std = nn.Parameter(torch.ones(1, N_ACTIONS) * 0.0)\n",
        "print(log_std.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icEw50_YmZiD",
        "outputId": "f5bcdad2-87b0-4812-c0b4-07cc38afdad5"
      },
      "source": [
        "c = log_std.exp()\n",
        "print(c, c.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1., 1.]], grad_fn=<ExpBackward>) torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1ziKhYnuJSl",
        "outputId": "0926a468-48a5-4bbf-e7eb-7010b296c28f"
      },
      "source": [
        "# mu = actor(state)\n",
        "mu = torch.FloatTensor([[0]*N_ACTIONS]) \n",
        "print(mu, mu.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 0.]]) torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYn8w1atmZiH"
      },
      "source": [
        "#expand as the size of mu\n",
        "std = log_std.exp().expand_as(mu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGhCm8MkmZiJ"
      },
      "source": [
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.normal_(m.weight, mean=0., std=0.1)\n",
        "        nn.init.constant_(m.bias, 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8myd-uUmZiK"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, ):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        self.actor = nn.Sequential(\n",
        "            nn.Linear(N_STATES, 128),\n",
        "            nn.LayerNorm(128),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.LayerNorm(128),\n",
        "            nn.Linear(128, N_ACTIONS)\n",
        "        )\n",
        "        self.log_std = nn.Parameter(torch.ones(1, N_ACTIONS) * 0.0)\n",
        "        self.apply(init_weights)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        mu    = self.actor(x)\n",
        "        std   = self.log_std.exp().expand_as(mu)\n",
        "        dist  = Normal(mu, std)\n",
        "        return dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq6Tvw6luJSm"
      },
      "source": [
        "### Generate two NNs - one learns to jump over small wall and the other learns to jump over big wall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B827GoiQmZiL"
      },
      "source": [
        "SmallWallNet = Net().to(device)\n",
        "BigWallNet = Net().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9utBxEvmZiM"
      },
      "source": [
        "### Use Small wall NN to interact with Unity scene for one step (Big wall NN is the same)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDAQoSNrmZiO"
      },
      "source": [
        "env = UnityEnvironment(file_name= None, base_port=5004)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY2NB7VmmZiR",
        "outputId": "1f5ff56a-730c-4f36-f50a-988d39b5652a"
      },
      "source": [
        "env.reset()\n",
        "behaviorNames = list(env.behavior_specs.keys())\n",
        "behaviorName = behaviorNames[0]\n",
        "print(behaviorName)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SmallWallJump?team=0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st-Zc2ACmZiS"
      },
      "source": [
        "DecisionSteps, TerminalSteps = env.get_steps(behaviorName)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qotPYCIVuJSp",
        "outputId": "6523222f-e7f3-4a22-b252-99b9cf1d757a"
      },
      "source": [
        "print(DecisionSteps.agent_id, TerminalSteps.agent_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1 2] []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeAtD4aimZiT",
        "outputId": "5a7cb928-597b-4307-8777-aad775c84ac9"
      },
      "source": [
        "print(DecisionSteps.obs[0].shape, DecisionSteps.obs[1].shape, DecisionSteps.obs[2].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3, 210) (3, 210) (3, 24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiLcXkZFuJSp",
        "outputId": "2275c7f8-d8d0-49b4-be40-9ad28f94615e"
      },
      "source": [
        "# test: practice tensor merge\n",
        "a = torch.tensor([[1, 2, 3],[1, 2, 3], [1, 2, 3]])\n",
        "b = torch.tensor([[4, 5, 6],[4, 5, 6], [4, 5, 6]])\n",
        "c = torch.tensor([[7], [8], [9]])\n",
        "print(a.shape, b.shape, c.shape)\n",
        "\n",
        "d = torch.cat((a, b, c), 1)\n",
        "print(d, d.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 3]) torch.Size([3, 3]) torch.Size([3, 1])\n",
            "tensor([[1, 2, 3, 4, 5, 6, 7],\n",
            "        [1, 2, 3, 4, 5, 6, 8],\n",
            "        [1, 2, 3, 4, 5, 6, 9]]) torch.Size([3, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koqzUQzTmZiU",
        "outputId": "70da837a-a393-4e82-f887-0150af5831f8"
      },
      "source": [
        "# merge vector observatin, perception \n",
        "s1 = torch.FloatTensor(DecisionSteps.obs[0])\n",
        "s2 = torch.FloatTensor(DecisionSteps.obs[1])\n",
        "s3 = torch.FloatTensor(DecisionSteps.obs[2])\n",
        "\n",
        "states = torch.cat((s1, s2, s3), 1).to(device)\n",
        "print(states.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 444])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vEN_XjQmZiW",
        "outputId": "11633cae-7c2a-4472-93ad-32e4a724d697"
      },
      "source": [
        "# send state to NN\n",
        "dist = SmallWallNet(states)\n",
        "print(dist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normal(loc: torch.Size([3, 4]), scale: torch.Size([3, 4]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSZXtwOcmZiW",
        "outputId": "a406d082-dc85-4122-8a2f-5b6e4e7a71d1"
      },
      "source": [
        "actions = dist.sample()\n",
        "print(actions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.4810,  0.4763,  2.5353, -1.3833],\n",
            "        [ 1.3642, -0.9851,  1.8801, -0.5936],\n",
            "        [ 0.5316, -0.8967,  2.5598,  0.1636]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SPGmm5-uJSq"
      },
      "source": [
        "#### Convert sampled action values to action indices <br />\n",
        "dirToGoForwardAction = act[0]  => 0, 1, 2<br />\n",
        "rotateDirAction = act[1]       => 0, 1, 2<br />\n",
        "dirToGoSideAction = act[2]     => 0, 1, 2<br />\n",
        "jumpAction = act[3]            => 0, 1<br />"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khFxXVm3uJSq",
        "outputId": "5b4693e2-a976-4177-864c-bda1607188ec"
      },
      "source": [
        "# find the cumulative density function evaluated at the sampled value\n",
        "actionCFD = dist.cdf(actions)\n",
        "print(actionCFD)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.1705, 0.7793, 0.6945, 0.3938],\n",
            "        [0.3669, 0.2046, 0.4522, 0.7293],\n",
            "        [0.2507, 0.1648, 0.7298, 0.9201]], device='cuda:0',\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gjUp1VHuJSr",
        "outputId": "87a6287c-28be-421b-fa98-fca5390ed8dc"
      },
      "source": [
        "# print agent's action branch and the value sampled by NN\n",
        "for agentID in range(N_AGENTS):\n",
        "    for idx, value in enumerate(actions[agentID]):\n",
        "        cfd = float(actionCFD[agentID][idx])\n",
        "        print(\"Agent\", agentID, \"=> Action branch\", idx, \",value \", value, \", cfd\", cfd)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent 0 => Action branch 0 ,value  tensor(0.4810, device='cuda:0') , cfd 0.17048412561416626\n",
            "Agent 0 => Action branch 1 ,value  tensor(0.4763, device='cuda:0') , cfd 0.779264509677887\n",
            "Agent 0 => Action branch 2 ,value  tensor(2.5353, device='cuda:0') , cfd 0.6944706439971924\n",
            "Agent 0 => Action branch 3 ,value  tensor(-1.3833, device='cuda:0') , cfd 0.39379215240478516\n",
            "Agent 1 => Action branch 0 ,value  tensor(1.3642, device='cuda:0') , cfd 0.3669050335884094\n",
            "Agent 1 => Action branch 1 ,value  tensor(-0.9851, device='cuda:0') , cfd 0.2046242654323578\n",
            "Agent 1 => Action branch 2 ,value  tensor(1.8801, device='cuda:0') , cfd 0.4522150754928589\n",
            "Agent 1 => Action branch 3 ,value  tensor(-0.5936, device='cuda:0') , cfd 0.7292628884315491\n",
            "Agent 2 => Action branch 0 ,value  tensor(0.5316, device='cuda:0') , cfd 0.2507057189941406\n",
            "Agent 2 => Action branch 1 ,value  tensor(-0.8967, device='cuda:0') , cfd 0.16483044624328613\n",
            "Agent 2 => Action branch 2 ,value  tensor(2.5598, device='cuda:0') , cfd 0.7298029065132141\n",
            "Agent 2 => Action branch 3 ,value  tensor(0.1636, device='cuda:0') , cfd 0.9201474785804749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIeltuliuJSr",
        "outputId": "8b3235ba-2958-4fd5-f7e8-d22a6437ad6a"
      },
      "source": [
        "# convert sampled value to index\n",
        "actionIdx = []\n",
        "for agentID in range(N_AGENTS):\n",
        "    agentActionIdx = []\n",
        "    for idx, value in enumerate(actions[agentID]):\n",
        "        cfd = float(actionCFD[agentID][idx])\n",
        "        if(idx <=2): #branch 0, 1, 2 => 3 action indices\n",
        "            if(cfd<0.33333):\n",
        "                agentActionIdx.append(0)\n",
        "            elif(cfd<0.66666):\n",
        "                agentActionIdx.append(1)\n",
        "            else:\n",
        "                agentActionIdx.append(2)\n",
        "        else: #branch 3 => 2 action indices\n",
        "            if(cfd<0.5):\n",
        "                agentActionIdx.append(0)\n",
        "            else:\n",
        "                agentActionIdx.append(1)\n",
        "    actionIdx.append(agentActionIdx)\n",
        "print(actionIdx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0, 2, 2, 0], [1, 0, 1, 1], [0, 0, 2, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miE3XZG8uJSr",
        "outputId": "0cfecfcf-bd76-4500-fbef-38f791e79ece"
      },
      "source": [
        "actionIdx = np.array(actionIdx)\n",
        "print(actionIdx.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bafHWOTwmZiZ"
      },
      "source": [
        "# send action indices to Unity\n",
        "env.set_actions(behaviorName, actionIdx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIFAs81jmZiZ"
      },
      "source": [
        "env.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSmdVPUDuJSs",
        "outputId": "b0853baf-bcc3-4fcb-a47b-604bb2412cb3"
      },
      "source": [
        "DecisionSteps, TerminalSteps = env.get_steps(behaviorName)\n",
        "print(DecisionSteps.agent_id, TerminalSteps.agent_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[] [0 1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsPx8EqFmZiZ"
      },
      "source": [
        "env.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLc6f989uJSs"
      },
      "source": [
        "### Define a function to convert sampled value to index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LsjqEluuJSs"
      },
      "source": [
        "def GenerateActionIndex(DecisionAgentNo, actions):\n",
        "    actionCFD = dist.cdf(actions)    \n",
        "    actionIdx = []\n",
        "    for agentID in range(DecisionAgentNo):\n",
        "        agentActionIdx = []\n",
        "        for idx, value in enumerate(actions[agentID]):\n",
        "            cfd = float(actionCFD[agentID][idx])\n",
        "            if(idx <=2): #branch 0, 1, 2 => 3 action indices\n",
        "                if(cfd<0.33333):\n",
        "                    agentActionIdx.append(0)\n",
        "                elif(cfd<0.66666):\n",
        "                    agentActionIdx.append(1)\n",
        "                else:\n",
        "                    agentActionIdx.append(2)\n",
        "            else: #branch 3 => 2 action indices\n",
        "                if(cfd<0.5):\n",
        "                    agentActionIdx.append(0)\n",
        "                else:\n",
        "                    agentActionIdx.append(1)\n",
        "        actionIdx.append(agentActionIdx)\n",
        "    return np.array(actionIdx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2z_K1TgmZiZ"
      },
      "source": [
        "# Two NNs (Small wall and Big wall) interact with Unity for N steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFKZGiOkuJSt"
      },
      "source": [
        "### Set Decision period=1 in Decision Requester component. Otherwise terminated agent will not recover"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODkkejoKuJSt"
      },
      "source": [
        "N_AGENTS = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enqzAfnCmZia"
      },
      "source": [
        "env = UnityEnvironment(file_name= None, base_port=5004)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGd6xFpnuJSt",
        "outputId": "c46fca51-2943-4dde-8f8c-051ad8ae83e1"
      },
      "source": [
        "#reset twice to get behaviors of this training environment\n",
        "env.reset()\n",
        "behaviorNames = list(env.behavior_specs.keys())\n",
        "env.reset()\n",
        "behaviorNames = list(env.behavior_specs.keys())\n",
        "print(behaviorNames)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['SmallWallJump?team=0', 'BigWallJump?team=0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuymApgvmZia",
        "outputId": "b0cce321-2193-49f2-e466-c0d6a905fe83"
      },
      "source": [
        "for frame in range(500):\n",
        "    for idx, behaviorName in enumerate(behaviorNames):\n",
        "        DecisionSteps, TerminalSteps = env.get_steps(behaviorName)\n",
        "        if(len(TerminalSteps)>0): #some agent terminates\n",
        "            print(behaviorName, \"Step\", frame, \", decision agents \", \\\n",
        "                  DecisionSteps.agent_id, \", terminated agents \", TerminalSteps.agent_id)    \n",
        "        if(len(DecisionSteps)==0):\n",
        "            print(behaviorName, \"step\", frame, \": no decision steps, reset!\")\n",
        "            env.reset()\n",
        "        else:\n",
        "            s1 = torch.FloatTensor(DecisionSteps.obs[0])\n",
        "            s2 = torch.FloatTensor(DecisionSteps.obs[1])\n",
        "            s3 = torch.FloatTensor(DecisionSteps.obs[2])\n",
        "            state = torch.cat((s1, s2, s3), 1).to(device)\n",
        "            if(idx==0):\n",
        "                dist = SmallWallNet(state)\n",
        "            else:\n",
        "                dist = BigWallNet(state)\n",
        "            action = dist.sample()\n",
        "            actionIdx = GenerateActionIndex(len(DecisionSteps), action)  \n",
        "            env.set_actions(behaviorName, actionIdx)   \n",
        "            env.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SmallWallJump?team=0 Step 0 , decision agents  [1 2] , terminated agents  [0 1 2]\n",
            "BigWallJump?team=0 Step 25 , decision agents  [] , terminated agents  [1]\n",
            "BigWallJump?team=0 step 25 : no decision steps, reset!\n",
            "SmallWallJump?team=0 Step 26 , decision agents  [] , terminated agents  [2]\n",
            "SmallWallJump?team=0 step 26 : no decision steps, reset!\n",
            "BigWallJump?team=0 Step 26 , decision agents  [1] , terminated agents  [0 2]\n",
            "SmallWallJump?team=0 Step 56 , decision agents  [] , terminated agents  [0]\n",
            "SmallWallJump?team=0 step 56 : no decision steps, reset!\n",
            "SmallWallJump?team=0 step 57 : no decision steps, reset!\n",
            "BigWallJump?team=0 Step 57 , decision agents  [] , terminated agents  [0 1 2]\n",
            "BigWallJump?team=0 step 57 : no decision steps, reset!\n",
            "SmallWallJump?team=0 Step 58 , decision agents  [1] , terminated agents  [0 2]\n",
            "SmallWallJump?team=0 step 70 : no decision steps, reset!\n",
            "SmallWallJump?team=0 step 71 : no decision steps, reset!\n",
            "SmallWallJump?team=0 step 72 : no decision steps, reset!\n",
            "BigWallJump?team=0 Step 72 , decision agents  [0 1] , terminated agents  [2]\n",
            "SmallWallJump?team=0 step 75 : no decision steps, reset!\n",
            "BigWallJump?team=0 Step 75 , decision agents  [] , terminated agents  [1]\n",
            "BigWallJump?team=0 step 75 : no decision steps, reset!\n",
            "SmallWallJump?team=0 Step 76 , decision agents  [0] , terminated agents  [1 2]\n",
            "BigWallJump?team=0 Step 82 , decision agents  [] , terminated agents  [1]\n",
            "BigWallJump?team=0 step 82 : no decision steps, reset!\n",
            "SmallWallJump?team=0 Step 83 , decision agents  [2] , terminated agents  [0]\n",
            "SmallWallJump?team=0 step 85 : no decision steps, reset!\n",
            "BigWallJump?team=0 Step 93 , decision agents  [] , terminated agents  [1]\n",
            "BigWallJump?team=0 step 93 : no decision steps, reset!\n",
            "SmallWallJump?team=0 Step 94 , decision agents  [] , terminated agents  [2]\n",
            "SmallWallJump?team=0 step 94 : no decision steps, reset!\n",
            "BigWallJump?team=0 Step 94 , decision agents  [1 2] , terminated agents  [0]\n",
            "BigWallJump?team=0 Step 100 , decision agents  [] , terminated agents  [2]\n",
            "BigWallJump?team=0 step 100 : no decision steps, reset!\n",
            "SmallWallJump?team=0 Step 101 , decision agents  [2] , terminated agents  [0]\n",
            "BigWallJump?team=0 Step 105 , decision agents  [] , terminated agents  [1]\n",
            "BigWallJump?team=0 step 105 : no decision steps, reset!\n",
            "SmallWallJump?team=0 Step 106 , decision agents  [0] , terminated agents  [2]\n",
            "SmallWallJump?team=0 step 116 : no decision steps, reset!\n",
            "SmallWallJump?team=0 Step 124 , decision agents  [] , terminated agents  [2]\n",
            "SmallWallJump?team=0 step 124 : no decision steps, reset!\n",
            "SmallWallJump?team=0 step 125 : no decision steps, reset!\n",
            "BigWallJump?team=0 Step 125 , decision agents  [1] , terminated agents  [0 2]\n",
            "SmallWallJump?team=0 Step 151 , decision agents  [] , terminated agents  [2]\n",
            "SmallWallJump?team=0 step 151 : no decision steps, reset!\n",
            "BigWallJump?team=0 Step 155 , decision agents  [1] , terminated agents  [0]\n",
            "SmallWallJump?team=0 Step 157 , decision agents  [] , terminated agents  [2]\n",
            "SmallWallJump?team=0 step 157 : no decision steps, reset!\n",
            "SmallWallJump?team=0 step 193 : no decision steps, reset!\n",
            "SmallWallJump?team=0 step 194 : no decision steps, reset!\n",
            "BigWallJump?team=0 Step 194 , decision agents  [] , terminated agents  [0 1 2]\n",
            "BigWallJump?team=0 step 194 : no decision steps, reset!\n",
            "SmallWallJump?team=0 Step 195 , decision agents  [] , terminated agents  [0 1 2]\n",
            "SmallWallJump?team=0 step 195 : no decision steps, reset!\n",
            "BigWallJump?team=0 Step 195 , decision agents  [1 2] , terminated agents  [0]\n",
            "SmallWallJump?team=0 Step 210 , decision agents  [] , terminated agents  [0]\n",
            "SmallWallJump?team=0 step 210 : no decision steps, reset!\n",
            "SmallWallJump?team=0 step 211 : no decision steps, reset!\n",
            "SmallWallJump?team=0 step 212 : no decision steps, reset!\n",
            "BigWallJump?team=0 Step 212 , decision agents  [] , terminated agents  [0 1 2]\n",
            "BigWallJump?team=0 step 212 : no decision steps, reset!\n",
            "SmallWallJump?team=0 Step 213 , decision agents  [0 1] , terminated agents  [2]\n",
            "BigWallJump?team=0 step 216 : no decision steps, reset!\n",
            "BigWallJump?team=0 step 223 : no decision steps, reset!\n",
            "BigWallJump?team=0 Step 230 , decision agents  [] , terminated agents  [0]\n",
            "BigWallJump?team=0 step 230 : no decision steps, reset!\n",
            "SmallWallJump?team=0 Step 231 , decision agents  [0 1] , terminated agents  [2]\n",
            "SmallWallJump?team=0 step 241 : no decision steps, reset!\n",
            "SmallWallJump?team=0 step 242 : no decision steps, reset!\n",
            "BigWallJump?team=0 Step 242 , decision agents  [1] , terminated agents  [0 2]\n",
            "BigWallJump?team=0 step 247 : no decision steps, reset!\n",
            "SmallWallJump?team=0 Step 248 , decision agents  [] , terminated agents  [0]\n",
            "SmallWallJump?team=0 step 248 : no decision steps, reset!\n",
            "BigWallJump?team=0 Step 248 , decision agents  [0 2] , terminated agents  [1]\n",
            "BigWallJump?team=0 step 253 : no decision steps, reset!\n",
            "SmallWallJump?team=0 step 259 : no decision steps, reset!\n",
            "SmallWallJump?team=0 step 271 : no decision steps, reset!\n",
            "BigWallJump?team=0 Step 275 , decision agents  [0 2] , terminated agents  [2]\n",
            "SmallWallJump?team=0 step 277 : no decision steps, reset!\n",
            "BigWallJump?team=0 Step 277 , decision agents  [1] , terminated agents  [0 2]\n",
            "BigWallJump?team=0 step 286 : no decision steps, reset!\n",
            "SmallWallJump?team=0 Step 287 , decision agents  [] , terminated agents  [2]\n",
            "SmallWallJump?team=0 step 287 : no decision steps, reset!\n",
            "BigWallJump?team=0 Step 287 , decision agents  [] , terminated agents  [0 1 2]\n",
            "BigWallJump?team=0 step 287 : no decision steps, reset!\n",
            "SmallWallJump?team=0 Step 288 , decision agents  [0] , terminated agents  [1 2]\n",
            "BigWallJump?team=0 Step 298 , decision agents  [1] , terminated agents  [2]\n",
            "SmallWallJump?team=0 Step 306 , decision agents  [] , terminated agents  [2]\n",
            "SmallWallJump?team=0 step 306 : no decision steps, reset!\n",
            "SmallWallJump?team=0 Step 311 , decision agents  [] , terminated agents  [2]\n",
            "SmallWallJump?team=0 step 311 : no decision steps, reset!\n",
            "BigWallJump?team=0 Step 311 , decision agents  [0 2] , terminated agents  [1]\n",
            "BigWallJump?team=0 Step 324 , decision agents  [] , terminated agents  [2]\n",
            "BigWallJump?team=0 step 324 : no decision steps, reset!\n",
            "SmallWallJump?team=0 Step 325 , decision agents  [0] , terminated agents  [1]\n",
            "BigWallJump?team=0 Step 359 , decision agents  [] , terminated agents  [1]\n",
            "BigWallJump?team=0 step 359 : no decision steps, reset!\n",
            "SmallWallJump?team=0 Step 360 , decision agents  [1 2] , terminated agents  [0]\n",
            "BigWallJump?team=0 step 363 : no decision steps, reset!\n",
            "SmallWallJump?team=0 Step 417 , decision agents  [] , terminated agents  [1]\n",
            "SmallWallJump?team=0 step 417 : no decision steps, reset!\n",
            "BigWallJump?team=0 Step 417 , decision agents  [1 2] , terminated agents  [0]\n",
            "BigWallJump?team=0 Step 434 , decision agents  [1 2] , terminated agents  [2]\n",
            "SmallWallJump?team=0 step 460 : no decision steps, reset!\n",
            "BigWallJump?team=0 Step 460 , decision agents  [0] , terminated agents  [2]\n",
            "BigWallJump?team=0 step 494 : no decision steps, reset!\n",
            "SmallWallJump?team=0 Step 495 , decision agents  [2] , terminated agents  [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksJ0aS0pmZib"
      },
      "source": [
        "env.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYsmycFCmZib"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}