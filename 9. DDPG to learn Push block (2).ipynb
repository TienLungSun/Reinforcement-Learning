{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque  \n",
    "from mlagents_envs.environment import UnityEnvironment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DDPG agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STATES  = 210  # 105+105\n",
    "N_ACTIONS = 1  # 1 branch with 7 values, move forward/backward, rotate R/L, move R/L \n",
    "N_AGENTS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = int(1e3) #int(1e5)        # replay buffer size\n",
    "BATCH_SIZE =  32   #128              # minibatch size\n",
    "GAMMA = 0.99                  # discount factor\n",
    "TAU = 1e-3                    # for soft update of target parameters\n",
    "LR_ACTOR = 1e-4               # learning rate of the actor \n",
    "LR_CRITIC = 1e-4              # learning rate of the critic\n",
    "WEIGHT_DECAY = 0.0            # L2 weight decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda GeForce GTX 1660 SUPER\n"
     ]
    }
   ],
   "source": [
    "if(torch.cuda.is_available()):\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(device, torch.cuda.get_device_name(0))\n",
    "else: \n",
    "    device= torch.device(\"cpu\")\n",
    "    print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load NN, reply buffer, and Agent class\n",
    "%run \"9. DDPG_NN_and_MemoryBuffer.ipynb\"   \n",
    "%run \"9. DDPG_Agent.ipynb\"       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size=N_STATES, action_size=N_ACTIONS, num_agents=N_AGENTS, random_seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's begin training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to convert action value [-1, 1] to index 0~6\n",
    "def GenerateActionIndex(acts):\n",
    "    result = []\n",
    "    for AgentIdx in range(N_AGENTS):\n",
    "        value = acts[AgentIdx][0]\n",
    "        interval = 2/7\n",
    "        lower = -1\n",
    "        for i in range(7):  #action index 0~6\n",
    "            upper = lower + (i+1)*interval\n",
    "            if(value >= lower and value <= upper):\n",
    "                result.append([i])\n",
    "                break\n",
    "            else:\n",
    "                lower = upper\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = UnityEnvironment(file_name= None, base_port=5004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PushBlock?team=0\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "behaviorNames = list(env.behavior_specs.keys())\n",
    "behaviorName = behaviorNames[0]\n",
    "print(behaviorName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes= 50  #5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_scores = []            #historical scores\n",
    "scores_average_window = 100    #Window size to calculate avg score    \n",
    "solved_score = 8               #avg score required to consider finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 1\tEpisode Score: -0.346\tAverage Score: -0.346\n",
      "Episode 2\tEpisode Score: -1.000\tAverage Score: -0.673\n",
      "Episode 3\tEpisode Score: -0.173\tAverage Score: -0.506\n",
      "Episode 4\tEpisode Score: -1.000\tAverage Score: -0.630\n",
      "Episode 5\tEpisode Score: -1.000\tAverage Score: -0.704\n",
      "Episode 6\tEpisode Score: -0.079\tAverage Score: -0.600\n",
      "Episode 7\tEpisode Score: -1.000\tAverage Score: -0.657\n",
      "Episode 8\tEpisode Score: -1.000\tAverage Score: -0.700\n",
      "Episode 9\tEpisode Score: -1.000\tAverage Score: -0.733\n",
      "Episode 10\tEpisode Score: -0.221\tAverage Score: -0.682\n",
      "Episode 11\tEpisode Score: -1.000\tAverage Score: -0.711\n",
      "Episode 12\tEpisode Score: -1.000\tAverage Score: -0.735\n",
      "Episode 13\tEpisode Score: -1.000\tAverage Score: -0.755\n",
      "Episode 14\tEpisode Score: -1.000\tAverage Score: -0.773\n",
      "Episode 15\tEpisode Score: -1.000\tAverage Score: -0.788\n",
      "Episode 16\tEpisode Score: -0.034\tAverage Score: -0.741\n",
      "Episode 17\tEpisode Score: -1.000\tAverage Score: -0.756\n",
      "Episode 18\tEpisode Score: -0.880\tAverage Score: -0.763\n",
      "Episode 19\tEpisode Score: -1.000\tAverage Score: -0.776\n",
      "Episode 20\tEpisode Score: -1.000\tAverage Score: -0.787\n",
      "Episode 21\tEpisode Score: -1.000\tAverage Score: -0.797\n",
      "Episode 22\tEpisode Score: -1.000\tAverage Score: -0.806\n",
      "Episode 23\tEpisode Score: -1.000\tAverage Score: -0.815\n",
      "Episode 24\tEpisode Score: -1.000\tAverage Score: -0.822\n",
      "Episode 25\tEpisode Score: -1.000\tAverage Score: -0.829\n",
      "Episode 26\tEpisode Score: -1.000\tAverage Score: -0.836\n",
      "Episode 27\tEpisode Score: -1.000\tAverage Score: -0.842\n",
      "Episode 28\tEpisode Score: -1.000\tAverage Score: -0.848\n",
      "Episode 29\tEpisode Score: -1.000\tAverage Score: -0.853\n",
      "Episode 30\tEpisode Score: -1.000\tAverage Score: -0.858\n",
      "Episode 31\tEpisode Score: -1.000\tAverage Score: -0.863\n",
      "Episode 32\tEpisode Score: -1.000\tAverage Score: -0.867\n",
      "Episode 33\tEpisode Score: -1.000\tAverage Score: -0.871\n",
      "Episode 34\tEpisode Score: -1.000\tAverage Score: -0.875\n",
      "Episode 35\tEpisode Score: -1.000\tAverage Score: -0.878\n",
      "Episode 36\tEpisode Score: -1.000\tAverage Score: -0.882\n",
      "Episode 37\tEpisode Score: -1.000\tAverage Score: -0.885\n",
      "Episode 38\tEpisode Score: -1.000\tAverage Score: -0.888\n",
      "Episode 39\tEpisode Score: -1.000\tAverage Score: -0.891\n",
      "Episode 40\tEpisode Score: -1.000\tAverage Score: -0.894\n",
      "Episode 41\tEpisode Score: -1.000\tAverage Score: -0.896\n",
      "Episode 42\tEpisode Score: -1.000\tAverage Score: -0.899\n",
      "Episode 43\tEpisode Score: -1.000\tAverage Score: -0.901\n",
      "Episode 44\tEpisode Score: -1.000\tAverage Score: -0.903\n",
      "Episode 45\tEpisode Score: -1.000\tAverage Score: -0.905\n",
      "Episode 46\tEpisode Score: -1.000\tAverage Score: -0.907\n",
      "Episode 47\tEpisode Score: -1.000\tAverage Score: -0.909\n",
      "Episode 48\tEpisode Score: -1.000\tAverage Score: -0.911\n",
      "Episode 49\tEpisode Score: -1.000\tAverage Score: -0.913\n",
      "Episode 50\tEpisode Score: -1.000\tAverage Score: -0.915\n",
      "Episode 51\tEpisode Score: -1.000\tAverage Score: -0.917\n",
      "Episode 52\tEpisode Score: -1.000\tAverage Score: -0.918\n",
      "Episode 53\tEpisode Score: -1.000\tAverage Score: -0.920\n",
      "Episode 54\tEpisode Score: -1.000\tAverage Score: -0.921\n",
      "Episode 55\tEpisode Score: -1.000\tAverage Score: -0.923\n",
      "Episode 56\tEpisode Score: -1.000\tAverage Score: -0.924\n",
      "Episode 57\tEpisode Score: -1.000\tAverage Score: -0.925\n",
      "Episode 58\tEpisode Score: -1.000\tAverage Score: -0.927\n",
      "Episode 59\tEpisode Score: -1.000\tAverage Score: -0.928\n",
      "Episode 60\tEpisode Score: -1.000\tAverage Score: -0.929\n",
      "Episode 61\tEpisode Score: -1.000\tAverage Score: -0.930\n",
      "Episode 62\tEpisode Score: -1.000\tAverage Score: -0.931\n",
      "Episode 63\tEpisode Score: -1.000\tAverage Score: -0.932"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-71eba1cfc381>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mActionIdxArray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGenerateActionIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbehaviorName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mActionIdxArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m# get next states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IE562\\lib\\site-packages\\mlagents_envs\\timers.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mhierarchical_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__qualname__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IE562\\lib\\site-packages\\mlagents_envs\\environment.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[0mstep_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_generate_step_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_env_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mhierarchical_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"communicator.exchange\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_communicator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexchange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mUnityCommunicatorStoppedException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Communicator has exited.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IE562\\lib\\site-packages\\mlagents_envs\\rpc_communicator.py\u001b[0m in \u001b[0;36mexchange\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0mmessage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munity_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoll_for_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IE562\\lib\\site-packages\\mlagents_envs\\rpc_communicator.py\u001b[0m in \u001b[0;36mpoll_for_timeout\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mlaunched\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \"\"\"\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout_wait\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m             raise UnityTimeOutException(\n\u001b[0;32m     97\u001b[0m                 \u001b[1;34m\"The Unity environment took too long to respond. Make sure that :\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IE562\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36mpoll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IE562\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36m_poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    328\u001b[0m                         _winapi.PeekNamedPipe(self._handle)[0] != 0):\n\u001b[0;32m    329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_get_more_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IE562\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    857\u001b[0m                         \u001b[0mtimeout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0mready_handles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_exhaustive_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwaithandle_to_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;31m# request that overlapped reads stop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\IE562\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    789\u001b[0m         \u001b[0mready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 791\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_winapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWaitForMultipleObjects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    792\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mWAIT_TIMEOUT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# loop from num_episodes\n",
    "for i_episode in range(1, num_episodes+1):\n",
    "    # reset the unity environment at the beginning of each episode\n",
    "    env.reset()    \n",
    "\n",
    "    # get initial state of the unity environment \n",
    "    DecisionSteps, TerminalSteps = env.get_steps(behaviorName)\n",
    "    s1 = DecisionSteps.obs[0]\n",
    "    s2 = DecisionSteps.obs[1]\n",
    "    states = np.concatenate((s1, s2), 1)\n",
    "    \n",
    "\t# reset the training agent for new episode\n",
    "    agent.reset()\n",
    "\n",
    "    # set the initial episode score to zero.\n",
    "    agent_scores = np.zeros(N_AGENTS)\n",
    "\n",
    "    # Run the episode training loop;\n",
    "    # At each loop step take an action as a function of the current state observations\n",
    "    # Based on the resultant environmental state (next_state) and reward received update the Agents Actor and Critic networks\n",
    "    # If environment episode is done, exit loop...\n",
    "    # Otherwise repeat until done == true \n",
    "    while (True):\n",
    "        # determine actions for the unity agents from current sate\n",
    "        actions = agent.act(states)\n",
    "\n",
    "        # send the actions to the unity agents in the environment and receive resultant environment information\n",
    "        ActionIdxArray = np.array(GenerateActionIndex(actions))\n",
    "        env.set_actions(behaviorName, ActionIdxArray)\n",
    "        env.step()\n",
    "\n",
    "        # get next states\n",
    "        NextDecisionSteps, NextTerminalSteps = env.get_steps(behaviorName)\n",
    "        \n",
    "        #if next decision step misses some agents, then exit episode loop, to begin new episode\n",
    "        if(len(NextDecisionSteps)!= N_AGENTS): \n",
    "            break\n",
    "        \n",
    "        # else next decision step contains all agents\n",
    "        s1 = NextDecisionSteps.obs[0]\n",
    "        s2 = NextDecisionSteps.obs[1]\n",
    "        next_states = np.concatenate((s1, s2), 1)\n",
    "        \n",
    "        dones = np.array([[0]]*N_AGENTS)\n",
    "        for AgentID in  NextTerminalSteps.agent_id:\n",
    "            dones[AgentID] = 1                \n",
    "        \n",
    "        rewards = NextDecisionSteps.reward\n",
    "        \n",
    "        #Send (S, A, R, S') info to the training agent for replay buffer (memory) and network updates\n",
    "        agent.step(states, ActionIdxArray, rewards, next_states, dones)\n",
    "\n",
    "        # set new states to current states for determining next actions\n",
    "        states = next_states\n",
    "\n",
    "        # Update episode score for each unity agent\n",
    "        agent_scores += rewards\n",
    "        \n",
    "        #if next terminal step contains some agents, we also exit episode loop\n",
    "        if(len(NextTerminalSteps) > 0): \n",
    "            break\n",
    "\n",
    "    # Add episode score to Scores and...\n",
    "    # Calculate mean score over last 100 episodes \n",
    "    # Mean score is calculated over current episodes until i_episode > 100\n",
    "    episode_scores.append(np.mean(agent_scores))\n",
    "    average_score = np.mean(episode_scores[i_episode-min(i_episode,scores_average_window):i_episode+1])\n",
    "\n",
    "    #Print current and average score\n",
    "    print('\\nEpisode {}\\tEpisode Score: {:.3f}\\tAverage Score: {:.3f}'.format(i_episode, episode_scores[i_episode-1], average_score), end=\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18,9))\n",
    "plt.plot(episode_scores[10000:])\n",
    "plt.ylim(-2, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained  Actor and Critic network weights \n",
    "torch.save(agent.actor_local.state_dict(),  \"ddpgActor.pth\")\n",
    "torch.save(agent.critic_local.state_dict(), \"ddpgCritic.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
