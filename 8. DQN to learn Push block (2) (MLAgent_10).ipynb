{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GRObB0mXmZhq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mlagents_envs.environment import UnityEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JTDJ8jn3mZh5",
    "outputId": "2903d42b-7074-42d1-baaa-9fd1da0b86da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "if(torch.cuda.is_available()):\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(device, torch.cuda.get_device_name(0))\n",
    "else: \n",
    "    device= torch.device(\"cpu\")\n",
    "    print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STATES  = 210  # 105+105\n",
    "N_ACTIONS = 6  # 1 branch with 6 values, move forward/backward, rotate R/L, move R/L \n",
    "N_AGENTS = 3\n",
    "\n",
    "hidden_units = 256 #from ymal file\n",
    "\n",
    "LEARNING_RATE = 0.0003\n",
    "MEMORY_CAPACITY = 500 #10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FGhCm8MkmZiJ"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = nn.Linear(N_STATES, hidden_units)\n",
    "        self.layer2 = nn.Linear(hidden_units, hidden_units)\n",
    "        self.out = nn.Linear(hidden_units, N_ACTIONS)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "g8myd-uUmZiK"
   },
   "outputs": [],
   "source": [
    "eval_net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "B827GoiQmZiL"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(eval_net.parameters(), lr=LEARNING_RATE)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 422)\n"
     ]
    }
   ],
   "source": [
    "MEMORY = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))  # (s, a, r, s_) \n",
    "print(MEMORY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interact with Unity to fill the memory<br /> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = UnityEnvironment(file_name= None, base_port=5004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PushBlock?team=0\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "behaviorNames = list(env.behavior_specs.keys())\n",
    "behaviorName = behaviorNames[0]\n",
    "print(behaviorName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Interact_with_Unity_one_step (DecisionSteps):\n",
    "    s1 = torch.FloatTensor(DecisionSteps.obs[0])\n",
    "    s2 = torch.FloatTensor(DecisionSteps.obs[1])\n",
    "    s = torch.cat((s1, s2), 1).to(device)\n",
    "    action = eval_net(s)\n",
    "    MaxIdxOfEachAgent = torch.unsqueeze(torch.max(action, 1)[1], 1)\n",
    "    ActionIdxArray = MaxIdxOfEachAgent.cpu().data.numpy()\n",
    "    env.set_actions(behaviorName, ActionIdxArray+1) \n",
    "    env.step()\n",
    "    return s, ActionIdxArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MemoryIdx = 0\n",
    "DecisionSteps, TerminalSteps = env.get_steps(behaviorName)\n",
    "while (MemoryIdx < MEMORY_CAPACITY):\n",
    "    if(len(DecisionSteps)==0):\n",
    "        print(\"Step\", MemoryIdx, \": no decision steps, reset!\")\n",
    "        env.reset()\n",
    "        DecisionSteps, TerminalSteps = env.get_steps(behaviorName)\n",
    "        continue\n",
    "\n",
    "    #interacts with Unity one step, but collect data only when all agents\n",
    "    #have decision steps\n",
    "    s, ActionIdxArray = Interact_with_Unity_one_step (DecisionSteps)\n",
    "    \n",
    "    NextDecisionSteps, NextTerminalSteps = env.get_steps(behaviorName)\n",
    "    if(len(DecisionSteps) != N_AGENTS or len(NextDecisionSteps) != N_AGENTS): \n",
    "        print(MemoryIdx, \"not all agents having decision steps\", \\\n",
    "              DecisionSteps.agent_id, \"next: \", NextDecisionSteps.agent_id)\n",
    "    else:\n",
    "        #after one step, if all agents have decision steps then collect data\n",
    "        #collect reward of this action from next decision and terminal steps\n",
    "        s1 = torch.FloatTensor(NextDecisionSteps.obs[0])\n",
    "        s2 = torch.FloatTensor(NextDecisionSteps.obs[1])\n",
    "        s_ = torch.cat((s1, s2), 1).to(device)\n",
    "        r = NextDecisionSteps.reward\n",
    "        for agentIdx in range(N_AGENTS):\n",
    "            transition = np.hstack((s[agentIdx].cpu().numpy(), ActionIdxArray[agentIdx], r[agentIdx], s_[agentIdx].cpu().numpy()))\n",
    "            MEMORY[MemoryIdx, :] = transition\n",
    "            MemoryIdx += 1\n",
    "            if(MemoryIdx == MEMORY_CAPACITY):\n",
    "                break\n",
    "    DecisionSteps, TerminalSteps = NextDecisionSteps, NextTerminalSteps  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Start to learn when memory is filled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 422)\n"
     ]
    }
   ],
   "source": [
    "# sample batch transitions\n",
    "sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)\n",
    "b_memory = MEMORY[sample_index, :]\n",
    "print(b_memory.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 210])\n"
     ]
    }
   ],
   "source": [
    "b_s = torch.FloatTensor(b_memory[:, :N_STATES]).to(device)\n",
    "print(b_s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "b_a = torch.LongTensor(b_memory[:, N_STATES:N_STATES+1].astype(int)).to(device)\n",
    "print(b_a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1])\n",
      "torch.Size([5, 210])\n"
     ]
    }
   ],
   "source": [
    "b_r = torch.FloatTensor(b_memory[:, N_STATES+1:N_STATES+2]).to(device)\n",
    "b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:]).to(device)\n",
    "print(b_r.shape)\n",
    "print(b_s_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 6])\n"
     ]
    }
   ],
   "source": [
    "tmp = eval_net(b_s)\n",
    "print(tmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "# take max. QValue \n",
    "q_eval = torch.gather(tmp, dim=1, index=b_a)\n",
    "print(q_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "# send s to NN, and max. QValue \n",
    "q_eval = eval_net(b_s).gather(1, b_a)\n",
    "print(q_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 6])\n"
     ]
    }
   ],
   "source": [
    "q_next = target_net(b_s_).detach()\n",
    "print(q_next.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_next.max(1)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)\n",
    "print(q_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss = loss_func(q_eval, q_target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "2. NN with policy interacts with 3D Ball (MLAgent 10).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
